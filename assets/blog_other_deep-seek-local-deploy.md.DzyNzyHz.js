import{m as t,c as s,b as a,ak as l}from"./chunks/framework.B7gcd-BE.js";const i="/apecode/assets/2025-03-14_22-46-28_deepseek.DFist4d2.png",p="/apecode/assets/2025-03-15_13-18-38_deepseek.Djz5jYQ_.png",n="/apecode/assets/2025-03-15_13-23-58_deepseek.CIfNB224.png",d="/apecode/assets/2025-03-15_13-31-20_deepseek.hbpCLKJ4.png",r="/apecode/assets/2025-03-15_13-35-14_deepseek.CMd72ImO.png",o="/apecode/assets/2025-03-15_13-39-27_deepseek.DwRLJSeB.png",c="/apecode/assets/2025-03-15_13-43-20_deepseek.341dUrzc.png",h="/apecode/assets/2025-03-15_13-49-26_deepseek.BvynMy29.png",k="/apecode/assets/2025-03-15_13-53-35_deepseek.B3L0gzss.png",g="/apecode/assets/2025-03-15_13-54-00_deepseek.CcbGNoQA.png",y="/apecode/assets/2025-03-15_15-15-58_deepseek.DpQAXFAO.png",m="/apecode/assets/2025-03-15_15-16-45_deepseek.CkptjyUe.png",_="/apecode/assets/2025-03-15_15-17-11_deepseek.CpPw3vPP.png",x="/apecode/assets/2025-03-15_15-17-53_deepseek.BSjCoYUW.png",S=JSON.parse('{"title":"DeepSeek 本地部署","description":"","frontmatter":{},"headers":[],"relativePath":"blog/other/deep-seek-local-deploy.md","filePath":"blog/other/deep-seek-local-deploy.md","lastUpdated":1742024535000}'),b={name:"blog/other/deep-seek-local-deploy.md"};function u(B,e,F,C,f,A){return a(),s("div",null,e[0]||(e[0]=[l('<h1 id="deepseek-本地部署" tabindex="-1">DeepSeek 本地部署 <a class="header-anchor" href="#deepseek-本地部署" aria-label="Permalink to &quot;DeepSeek 本地部署&quot;">​</a></h1><blockquote><p>随着 DeepSeek 的爆火，以及官方网站的响应时间越来越长，甚至提示服务器繁忙。于是萌生了本地部署的想法。</p></blockquote><p>会学到什么：</p><ol><li>了解 DeepSeek 的各个版本的运行要求</li><li>借助 Ollama 部署 DeepSeek（将安装 R1 1.5b 版本）</li><li>常见的 WebUI</li></ol><h2 id="运行要求" tabindex="-1">运行要求 <a class="header-anchor" href="#运行要求" aria-label="Permalink to &quot;运行要求&quot;">​</a></h2><p>不同版本模型硬件要求</p><table tabindex="0"><thead><tr><th style="text-align:center;">模型版本</th><th style="text-align:center;">参数量</th><th style="text-align:center;">显存需求（FP16）</th><th style="text-align:center;">推荐 GPU（单卡）</th><th style="text-align:center;">多卡支持</th><th style="text-align:center;">量化支持</th><th style="text-align:center;">适用场景</th></tr></thead><tbody><tr><td style="text-align:center;">DeepSeek-R1-1.5B</td><td style="text-align:center;">15 亿</td><td style="text-align:center;">3GB</td><td style="text-align:center;">GTX 1650（4GB 显存）</td><td style="text-align:center;">无需</td><td style="text-align:center;">支持</td><td style="text-align:center;">低资源设备部署（树莓派、旧款笔记本）、实时文本生成、嵌入式系统</td></tr><tr><td style="text-align:center;">DeepSeek-R1-7B</td><td style="text-align:center;">70 亿</td><td style="text-align:center;">14GB</td><td style="text-align:center;">RTX 3070/4060（8GB 显存）</td><td style="text-align:center;">可选</td><td style="text-align:center;">支持</td><td style="text-align:center;">中等复杂度任务（文本摘要、翻译）、轻量级多轮对话系统</td></tr><tr><td style="text-align:center;">DeepSeek-R1-8B</td><td style="text-align:center;">80 亿</td><td style="text-align:center;">16GB</td><td style="text-align:center;">RTX 4070（12GB 显存）</td><td style="text-align:center;">可选</td><td style="text-align:center;">支持</td><td style="text-align:center;">需更高精度的轻量级任务（代码生成、逻辑推理）</td></tr><tr><td style="text-align:center;">DeepSeek-R1-14B</td><td style="text-align:center;">140 亿</td><td style="text-align:center;">32GB</td><td style="text-align:center;">RTX 4090/A5000（16GB 显存）</td><td style="text-align:center;">推荐</td><td style="text-align:center;">支持</td><td style="text-align:center;">企业级复杂任务（合同分析、报告生成）、长文本理解与生成</td></tr><tr><td style="text-align:center;">DeepSeek-R1-32B</td><td style="text-align:center;">320 亿</td><td style="text-align:center;">64GB</td><td style="text-align:center;">A100 40GB（24GB 显存）</td><td style="text-align:center;">推荐</td><td style="text-align:center;">支持</td><td style="text-align:center;">高精度专业领域任务（医疗/法律咨询）、多模态任务预处理</td></tr><tr><td style="text-align:center;">DeepSeek-R1-70B</td><td style="text-align:center;">700 亿</td><td style="text-align:center;">140GB</td><td style="text-align:center;">2x A100 80GB/4x RTX 4090（多卡并行）</td><td style="text-align:center;">必需</td><td style="text-align:center;">支持</td><td style="text-align:center;">科研机构/大型企业（金融预测、大规模数据分析）、高复杂度生成任务</td></tr><tr><td style="text-align:center;">DeepSeek-671B</td><td style="text-align:center;">6710 亿</td><td style="text-align:center;">512GB+（单卡显存需求极高，通常需要多节点分布式训练）</td><td style="text-align:center;">8x A100/H100（服务器集群）</td><td style="text-align:center;">必需</td><td style="text-align:center;">支持</td><td style="text-align:center;">国家级/超大规模 AI 研究（气候建模、基因组分析）、通用人工智能（AGI）探索</td></tr></tbody></table><h2 id="安装-ollama" tabindex="-1">安装 Ollama <a class="header-anchor" href="#安装-ollama" aria-label="Permalink to &quot;安装 Ollama&quot;">​</a></h2><p><code>ollama</code> 是一个用于本地运行和管理 大语言模型（LLMs） 的开源工具，可以通过它在本地轻松下载、运行和交互各种 AI 语言模型，而不依赖云端 API，提高了数据隐私性和响应速度。</p><p>下载：<a href="https://ollama.com/" target="_blank" rel="noreferrer">ollama</a></p><p><img src="'+i+'" alt="deepseek"></p><p>安装：</p><p><img src="'+p+'" alt="deepseek"></p><p>安装完成后，可通过终端检验 ollama 是否安装成功。如输出 <code>ollama version is 0.6.0</code> 等字样，说明已经安装成功。</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> -v</span></span></code></pre></div><p><img src="'+n+'" alt="deepseek"></p><h2 id="安装并运行-deepseek" tabindex="-1">安装并运行 DeepSeek <a class="header-anchor" href="#安装并运行-deepseek" aria-label="Permalink to &quot;安装并运行 DeepSeek&quot;">​</a></h2><p>在上一步中，我们已经完成了 ollama 的安装，且在终端执行验证了 ollama 的指令。随后开始对 deepseek 的安装。</p><p><img src="'+d+`" alt="deepseek"></p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 运行 deepseek-r1 1.5b 模型</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 初次运行该模型时，会自动下载</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 指令参数详情：https://ollama.com/library/deepseek-r1:1.5b</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">ollama</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> run</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> deepseek-r1:1.5b</span></span></code></pre></div><p><img src="`+r+'" alt="deepseek"></p><div class="warning custom-block"><p class="custom-block-title">可能遇到的问题</p><div class="language-shell vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">shell</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">Error:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> pull</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> model</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> manifest:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> Get</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;https://registry.ollama.ai/v2/library/deepseek-r1/manifests/1.5b&quot;:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> net/http:</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> TLS</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> handshake</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> timeout</span></span></code></pre></div><p>安装 deepseek 时，如出现超时情况，可能是因为代理的问题，尝试关闭代理并重新执行安装命令即可。</p></div><p>运行成功后，会出现 <code>Send a message</code> 字样，说明已经成功在本地运行 deepseek。</p><p><img src="'+o+'" alt="deepseek"></p><p><img src="'+c+'" alt="deepseek"></p><p>截至，已经完成了 deepseek 本地部署操作，但不难发现直接再终端上交互，体验感并不好。</p><h2 id="webui" tabindex="-1">WebUI <a class="header-anchor" href="#webui" aria-label="Permalink to &quot;WebUI&quot;">​</a></h2><p>为了优化交互体验，市面上有两个工具结合使用，可以根据各自的爱好自行选择一个即可。</p><h3 id="page-assit" tabindex="-1">Page Assit <a class="header-anchor" href="#page-assit" aria-label="Permalink to &quot;Page Assit&quot;">​</a></h3><p>这是一个浏览器插件。</p><p><a href="https://chromewebstore.google.com/detail/page-assist-%E6%9C%AC%E5%9C%B0-ai-%E6%A8%A1%E5%9E%8B%E7%9A%84-web/jfgfiigpkhlkbnfnbobbkinehhfdhndo?hl=zh-cn" target="_blank" rel="noreferrer">Page Assit 安装 👉</a></p><p><img src="'+h+'" alt="deepseek"></p><p>安装成功后，点击浏览器插件的 Page Assit 图标，将自动打开一个界面。</p><p><img src="'+k+'" alt="deepseek"></p><p><img src="'+g+'" alt="deepseek"></p><p>输入内容，提交即可。</p><h3 id="chatbox" tabindex="-1">Chatbox <a class="header-anchor" href="#chatbox" aria-label="Permalink to &quot;Chatbox&quot;">​</a></h3><p>这是一个客户端程序。</p><p><a href="https://chatboxai.app/zh" target="_blank" rel="noreferrer">Chatbox 官网 👉</a></p><p>下载、安装、打开。</p><p>选择“使用自己的 API Key 或本地模型”，选择 ollama API，选择 deepseek-r1:1.5b 模型保存，即可使用。</p><p><img src="'+y+'" alt="deepseek"></p><p><img src="'+m+'" alt="deepseek"></p><p><img src="'+_+'" alt="deepseek"></p><p><img src="'+x+'" alt="deepseek"></p><h2 id="参考资料" tabindex="-1">参考资料 <a class="header-anchor" href="#参考资料" aria-label="Permalink to &quot;参考资料&quot;">​</a></h2><ol><li><p><a href="https://www.cnblogs.com/xiezhr/p/18712410" target="_blank" rel="noreferrer">本地部署 DeepSeek：小白也能轻松搞定！</a></p></li><li><p><a href="https://deepseek.csdn.net/67abf83159bcf8384ab65a7a.html" target="_blank" rel="noreferrer">最简洁 DeepSeek 本地部署教程</a></p></li></ol>',47)]))}const v=t(b,[["render",u]]);export{S as __pageData,v as default};
